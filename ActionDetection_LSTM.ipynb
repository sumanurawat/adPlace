{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1567
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 137970,
     "status": "ok",
     "timestamp": 1558980636956,
     "user": {
      "displayName": "Jam Club",
      "photoUrl": "",
      "userId": "11638566925689659071"
     },
     "user_tz": -330
    },
    "id": "BKfn2eQcH82P",
    "outputId": "538c879f-0b98-482b-b222-d9587b70a29c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "!git clone https://github.com/mohammed-elkomy/two-stream-action-recognition.git\n",
    "os.chdir(\"/content/two-stream-action-recognition\")\n",
    "\n",
    "!git clone https://github.com/circulosmeos/gdown.pl.git\n",
    "!./gdown.pl/gdown.pl https://drive.google.com/file/d/1djGzpxAYFvNX-UaQ7ONqDHGgnzc8clBK/view \"spatial.zip\" \n",
    "!./gdown.pl/gdown.pl https://drive.google.com/file/d/1kvslNL8zmZYaHRmhgAM6-l_pNDDA0EKZ/view \"motion.zip\"\n",
    "!unzip spatial.zip\n",
    "!unzip motion.zip\n",
    "\n",
    "!pip install -U -q PyDrive 2> s.txt >> s.txt\n",
    "!pip install opencv-python 2> s.txt >> s.txt\n",
    "!pip install imgaug 2> s.txt >> s.txt\n",
    "!pip install scikit-video 2> s.txt >> s.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1734
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4284,
     "status": "ok",
     "timestamp": 1558980646053,
     "user": {
      "displayName": "Jam Club",
      "photoUrl": "",
      "userId": "11638566925689659071"
     },
     "user_tz": -330
    },
    "id": "dOpFZX1RJ8P3",
    "outputId": "e7f1c3b1-0cbb-4809-de58-8a678f71105e"
   },
   "outputs": [],
   "source": [
    "%cat ./UCF_list/classInd.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ueiAWww0IGy4"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from evaluation import legacy_load_model\n",
    "from evaluation.evaluation import *\n",
    "\n",
    "import random\n",
    "from frame_dataloader import DataUtil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import skvideo.io\n",
    "\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoKxy0tAYmKu"
   },
   "outputs": [],
   "source": [
    "#Category mapping - 101 into n categories\n",
    "import csv\n",
    "import collections\n",
    "filepath = '/content/two-stream-action-recognition/drive/My Drive/adplace/actionoutput.csv'\n",
    "mappingDict = collections.OrderedDict()\n",
    "mappingDict = {\n",
    "    \"ApplyEyeMakeup\" : 1,\n",
    "    \"ApplyLipstick\" : 1,\n",
    "    \"Archery\" : 2,\n",
    "    \"BabyCrawling\" : 1,\n",
    "    \"BalanceBeam\" : 2,\n",
    "    \n",
    "    \"BandMarching\" : 2,\n",
    "    \"BaseballPitch\" : 3,\n",
    "    \"Basketball\" : 3,\n",
    "    \"Basketball\" : 3,\n",
    "    \"BenchPress\" : 2,\n",
    "    \n",
    "    \"Biking\" : 3,\n",
    "    \"Billiards\" : 2,\n",
    "    \"BlowDryHair\" : 1,\n",
    "    \"BlowingCandles\" : 1,\n",
    "    \"BodyWeightSquats\" : 1,\n",
    "    \n",
    "    \"Bowling\" : 2,\n",
    "    \"BoxingPunchingBag\" : 2,\n",
    "    \"BoxingSpeedBag\" : 2,\n",
    "    \"BreastStroke\" : 3,\n",
    "    \"BrushingTeeth\" : 1,\n",
    "    \n",
    "    \"CleanAndJerk\" : 1,\n",
    "    \"CliffDiving\" : 3,\n",
    "    \"CricketBowling\" : 2,\n",
    "    \"CricketShot\" : 3,\n",
    "    \"CuttingInKitchen\" : 1,\n",
    "    \n",
    "    \"Diving\" : 3,\n",
    "    \"Drumming\" : 3,\n",
    "    \"Fencing\" : 1,\n",
    "    \"FieldHockeyPenalty\" : 3,\n",
    "    \"FloorGymnastics\" : 3,\n",
    "    \n",
    "    \"FrisbeeCatch\" : 2,\n",
    "    \"FrontCrawl\" : 1,\n",
    "    \"GolfSwing\" : 2,\n",
    "    \"Haircut\" : 1,\n",
    "    \"Hammering\" : 1,\n",
    "    \n",
    "    \"HammerThrow\" : 1,\n",
    "    \"HandstandPushups\" : 2,\n",
    "    \"HandstandWalking\" : 3,\n",
    "    \"HeadMassage\" : 1,\n",
    "    \"HighJump\" : 2,\n",
    "    \n",
    "    \"HorseRace\" : 3,\n",
    "    \"HorseRiding\" : 3,\n",
    "    \"HulaHoop\" : 2,\n",
    "    \"IceDancing\" : 3,\n",
    "    \"JavelinThrow\" : 2,\n",
    "    \n",
    "    \"JugglingBalls\" : 3,\n",
    "    \"JumpingJack\" : 3,\n",
    "    \"JumpRope\" : 2,\n",
    "    \"Kayaking\" : 3,\n",
    "    \"Knitting\" : 1,\n",
    "    \n",
    "    \"LongJump\" : 2,\n",
    "    \"Lunges\" : 2,\n",
    "    \"MilitaryParade\" : 2,\n",
    "    \"Mixing\" : 1,\n",
    "    \"MoppingFloor\" : 1,\n",
    "    \n",
    "    \"Nunchucks\" : 2,\n",
    "    \"ParallelBars\" : 2,\n",
    "    \"PizzaTossing\" : 2,\n",
    "    \"PlayingCello\" : 2,\n",
    "    \"PlayingDaf\" : 2,\n",
    "    \n",
    "    \"PlayingDhol\" : 3,\n",
    "    \"PlayingFlute\" : 3,\n",
    "    \"PlayingGuitar\" : 3,\n",
    "    \"PlayingPiano\" : 3,\n",
    "    \"PlayingSitar\" : 2,\n",
    "    \n",
    "    \"PlayingTabla\" : 2,\n",
    "    \"PlayingViolin\" : 2,\n",
    "    \"PoleVault\" : 2,\n",
    "    \"PommelHorse\" : 2,\n",
    "    \"PullUps\" : 2,\n",
    "    \n",
    "    \"Punch\" : 2,\n",
    "    \"PushUps\" : 2,\n",
    "    \"Rafting\" : 3,\n",
    "    \"RockClimbingIndoor\" : 3,\n",
    "    \"RopeClimbing\" : 3,\n",
    "    \n",
    "    \"Rowing\" : 3,\n",
    "    \"SalsaSpin\" : 3,\n",
    "    \"ShavingBeard\" : 1,\n",
    "    \"Shotput\" : 2,\n",
    "    \"SkateBoarding\" : 3,\n",
    "    \n",
    "    \"Skiing\" : 3,\n",
    "    \"Skijet\" : 3,\n",
    "    \"SkyDiving\" : 3,\n",
    "    \"SoccerJuggling\" : 3,\n",
    "    \"SoccerPenalty\" : 3,\n",
    "    \n",
    "    \"StillRings\" : 2,\n",
    "    \"SumoWrestling\" : 2,\n",
    "    \"Surfing\" : 3,\n",
    "    \"Swing\" : 2,\n",
    "    \"TableTennisShot\" : 3,\n",
    "    \n",
    "    \"TaiChi\" : 2,\n",
    "    \"TennisSwing\" : 3,\n",
    "    \"ThrowDiscus\" : 2,\n",
    "    \"TrampolineJumping\" : 3,\n",
    "    \"Typing\" : 1,\n",
    "    \n",
    "    \"UnevenBars\" : 1,\n",
    "    \"VolleyballSpiking\" : 2,\n",
    "    \"WalkingWithDog\" : 2,\n",
    "    \"WallPushups\" : 2,\n",
    "    \"WritingOnBoard\" : 1,\n",
    "    \n",
    "    \"YoYo\" : 2\n",
    "}\n",
    "category_list_in_order = [1,1,2,1,2,2,3,3,3,2,3,2,1,1,1,2,2,2,3,1,1,3,2,3,1,3,3,1,3,3,2,1,2,1,1,1,2,3,1,2,3,3,2,3,2,3,3,2,3,1,2,2,2,1,1,2,2,2,2,2,2,2,3,3,3,3,3,1,2,3,3,3,3,3,3,2,2,3,2,3,2,3,2,3,1,1,2,2,2,1,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4N_PrXwmY1b0"
   },
   "outputs": [],
   "source": [
    "def getValueFromKey(key):\n",
    "  return mappingDict[key]\n",
    "\n",
    "def writeToCSV(filename, category):\n",
    "  with open(filepath, 'a') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([filename, category])\n",
    "    \n",
    "def postLstmOps(filename, action):\n",
    "  category = getValueFromList(action)\n",
    "  writeToCSV(filename, category)\n",
    " \n",
    "\n",
    "def getValueFromList(index):\n",
    "  return category_list_in_order[index]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1516,
     "status": "ok",
     "timestamp": 1558980670443,
     "user": {
      "displayName": "Jam Club",
      "photoUrl": "",
      "userId": "11638566925689659071"
     },
     "user_tz": -330
    },
    "id": "H2OBzAHBJPmz",
    "outputId": "ce654db7-67fa-433a-ca58-e0ff30d3d293"
   },
   "outputs": [],
   "source": [
    "# defining functions and global objects\n",
    "\n",
    "# dictionary of class names\n",
    "data_util = DataUtil(path= './UCF_list/', split=\"01\")\n",
    "action_names =  {v:k for k,v in data_util.action_to_label.items()} # class name dictionary\n",
    "print (action_names)\n",
    "stacked_frames = 10\n",
    "\n",
    "# image resize augmenter to be fed into the network\n",
    "augmenter = iaa.Sequential([\n",
    "    iaa.Resize({\"height\": 299, \"width\": 299})\n",
    "])\n",
    "\n",
    "\n",
    "def convert_to_image(flow_image):\n",
    "    \"\"\"\n",
    "    this is the conversion function of each flow frame\n",
    "    based on the cpp version of extracting optical flow https://github.com/feichtenhofer/gpu_flow/blob/master/compute_flow.cpp\n",
    "    \"\"\"\n",
    "    l, h = -20, 20\n",
    "    return (255 * (flow_image - l) / (h - l)).astype(np.uint8)\n",
    "\n",
    "\n",
    "def stack_opticalflow(start_frame_index, stacked_frames):  # returns numpy (h,w,stacked*2) = one sample\n",
    "    \"\"\"\n",
    "    Stacks \"stacked_frames\" u/v frames on a single numpy array : (h,w,stacked*2)\n",
    "    \"\"\"\n",
    "    first_optical_frame_u = original_u_frames[start_frame_index]  # horizontal\n",
    "    first_optical_frame_v = original_v_frames[start_frame_index]  # vertical\n",
    "\n",
    "    stacked_optical_flow_sample = np.zeros(first_optical_frame_u.shape + (2 * stacked_frames,), dtype=np.uint8)  # with channel dimension of  stacked_frames(u)+ stacked_frames(v)\n",
    "\n",
    "    stacked_optical_flow_sample[:, :, 0] = first_optical_frame_u\n",
    "    stacked_optical_flow_sample[:, :, 0 + stacked_frames] = first_optical_frame_v\n",
    "\n",
    "    for index, optical_frame_id in enumerate(range(start_frame_index + 1, start_frame_index + stacked_frames), 1):  # index starts at 1 placed after the first one\n",
    "        stacked_optical_flow_sample[:, :, index] = original_u_frames[optical_frame_id]\n",
    "        stacked_optical_flow_sample[:, :, index + stacked_frames] = original_v_frames[optical_frame_id]\n",
    "\n",
    "    return stacked_optical_flow_sample\n",
    "\n",
    "\n",
    "def get_image_from_fig(fig):\n",
    "    \"\"\"\n",
    "    converts matplotlib figure into a numpy array for demo video generation\n",
    "    \"\"\"\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99704,
     "status": "ok",
     "timestamp": 1558980777344,
     "user": {
      "displayName": "Jam Club",
      "photoUrl": "",
      "userId": "11638566925689659071"
     },
     "user_tz": -330
    },
    "id": "fmPHi8HQOK8s",
    "outputId": "1e56b80e-99a8-433f-9291-29326a73807f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# legacy_load_model is an older version of keras load_model since keras API changed a little bit when I was working on action recognition \n",
    "\n",
    "# load into ram\n",
    "print(\"Loading Spatial stream\")\n",
    "spatial_model_restored = legacy_load_model(filepath=\"spatial.h5\", custom_objects={'sparse_categorical_cross_entropy_loss': sparse_categorical_cross_entropy_loss, \"acc_top_1\": acc_top_1, \"acc_top_5\": acc_top_5})\n",
    "spatial_model_restored.summary()\n",
    "\n",
    "\n",
    "# load into ram\n",
    "print(\"Loading Motion stream\")\n",
    "motion_model_restored = legacy_load_model(filepath=\"motion.h5\", custom_objects={'sparse_categorical_cross_entropy_loss': sparse_categorical_cross_entropy_loss, \"acc_top_1\": acc_top_1, \"acc_top_5\": acc_top_5})\n",
    "motion_model_restored.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1509,
     "status": "ok",
     "timestamp": 1558980786049,
     "user": {
      "displayName": "Jam Club",
      "photoUrl": "",
      "userId": "11638566925689659071"
     },
     "user_tz": -330
    },
    "id": "Zyuy_0MXK3no",
    "outputId": "b664f496-261e-46c9-ebd9-8ae75c8e05c5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 15011
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4305,
     "status": "ok",
     "timestamp": 1558980847066,
     "user": {
      "displayName": "Jam Club",
      "photoUrl": "",
      "userId": "11638566925689659071"
     },
     "user_tz": -330
    },
    "id": "apq7hwk3fx8x",
    "outputId": "2bc3beda-dc50-41b5-aff2-44c873292266"
   },
   "outputs": [],
   "source": [
    "%ls '/content/two-stream-action-recognition/drive/My Drive/adplace/scene_videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1875,
     "status": "error",
     "timestamp": 1559026256096,
     "user": {
      "displayName": "Jam Club",
      "photoUrl": "",
      "userId": "11638566925689659071"
     },
     "user_tz": -330
    },
    "id": "ckfhvh3VP8XW",
    "outputId": "78a5765e-1072-4b66-90a3-0394570f322b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# select a random video\n",
    "video_dir=\"/content/two-stream-action-recognition/drive/My Drive/adplace/scene_videos/\"\n",
    "videos = os.listdir(video_dir)\n",
    "print(videos)\n",
    "for video in videos:\n",
    "  video_path = video_dir+video\n",
    "  print(\"selected_video:\",video_path)\n",
    "  vidcap = cv2.VideoCapture(selected_video)\n",
    "  print(\"frame rate for demo:\",vidcap.get(cv2.CAP_PROP_FPS))\n",
    "  success, image = vidcap.read()\n",
    "  # make the rgb frames\n",
    "  original_rgb_frames = []\n",
    "\n",
    "  while success:\n",
    "      original_rgb_frames.append(image)\n",
    "      success, image = vidcap.read()\n",
    "\n",
    "  print(\"frames count in video\", len(original_rgb_frames))\n",
    "\n",
    "  # make the optical flow frames\n",
    "  original_v_frames = []\n",
    "  original_u_frames = []\n",
    "\n",
    "  frames = list(map(lambda frame: cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0, original_rgb_frames))\n",
    "  optical_flow = cv2.DualTVL1OpticalFlow_create()\n",
    "\n",
    "  for frame_index in range(len(frames) - 1):\n",
    "      if frame_index % 50 == 0:\n",
    "          print(\"processing tvl flow of frame \",frame_index)\n",
    "\n",
    "      flow = optical_flow.calc(frames[frame_index], frames[frame_index + 1], None)\n",
    "      u_frame = convert_to_image(flow[..., 0])\n",
    "      v_frame = convert_to_image(flow[..., 1])\n",
    "\n",
    "      original_v_frames.append(v_frame)\n",
    "      original_u_frames.append(u_frame)\n",
    "\n",
    "  print(\"original_rgb_frames:\", len(original_rgb_frames), \"original_u_frames:\", len(original_u_frames), \"original_v_frames:\", len(original_v_frames))\n",
    "  # generate spatial batch as done in the dataloader\n",
    "  spatial_batch = []\n",
    "  for image in original_rgb_frames:\n",
    "      spatial_batch.append(\n",
    "          cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      )\n",
    "\n",
    "  spatial_batch = np.array(augmenter.augment_images(spatial_batch), dtype=np.float32) / 255.0\n",
    "\n",
    "  # generate motion batch as done in the dataloader\n",
    "  motion_batch = []\n",
    "\n",
    "  for first_optical_frame_id in range(len(original_u_frames) - stacked_frames):\n",
    "      motion_batch.append(  # append one sample which is (h,w,stacked*2)\n",
    "          stack_opticalflow(start_frame_index=first_optical_frame_id, stacked_frames=stacked_frames)\n",
    "      )\n",
    "  motion_batch = np.array(augmenter.augment_images(motion_batch), dtype=np.float32) / 255.0\n",
    "\n",
    "  \"\"\"\n",
    "  predict spatial stream output\n",
    "  \"\"\"\n",
    "  spatial_pred = spatial_model_restored.predict(spatial_batch)\n",
    "  spatial_classes = np.argsort(spatial_pred,axis=1)[:,:-6:-1]\n",
    "  spatial_scores = np.sort(spatial_pred,axis=1)[:,:-6:-1]\n",
    "  \"\"\"\n",
    "  predict motion stream output\n",
    "  \"\"\"\n",
    "  motion_pred = motion_model_restored.predict(motion_batch)\n",
    "  motion_classes = np.argsort(motion_pred,axis=1)[:,:-6:-1]\n",
    "  motion_scores = np.sort(motion_pred,axis=1)[:,:-6:-1]\n",
    "  \"\"\"\n",
    "  get the average output prediction\n",
    "  \"\"\"\n",
    "  average_pred = motion_pred + spatial_pred[:motion_pred.shape[0],]\n",
    "  average_classes = np.argsort(average_pred,axis=1)[:,:-6:-1]\n",
    "  average_scores = np.sort(average_pred,axis=1)[:,:-6:-1]\n",
    "\n",
    "  final_class = []\n",
    "  # generating output video\n",
    "  for frame_index in range(motion_classes.shape[0]): \n",
    "    if frame_index % 50 == 0:\n",
    "        print(\"processing frame \",frame_index)\n",
    "    final_class.append(average_classes[frame_index][0])\n",
    "\n",
    "  print(final_class)\n",
    "  class_dict = {}\n",
    "  for frame_class in final_class:\n",
    "    class_dict[frame_class] = class_dict.get(frame_class, 0) + 1\n",
    "  final_class_index = max(class_dict, key=class_dict.get)\n",
    "  print(final_class_index)\n",
    "  postLstmOps(video,final_class_index)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ActionDetection.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
